{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.text import Text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports data made by title_lemmas.py, which has converted all words in the title to their lemma form. Divides articles into two categories, articles with less than 1000 reads and articles with more than 1000 reads. This split was chosen, because this divides the articles into half minimizing class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>title</th>\n",
       "      <th>share_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>read_count</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6839008</td>\n",
       "      <td>2019-11-30T13:50:49+02:00</td>\n",
       "      <td>Tänavatantsijad tõid Leedu võistluselt Tartuss...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>{'Lenel Karu'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6838978</td>\n",
       "      <td>2019-11-30T12:49:30+02:00</td>\n",
       "      <td>Tartu ärinõuandla andis välja Hea Tegu auhinnad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>{'Tartu Postimees'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6838938</td>\n",
       "      <td>2019-11-30T11:08:41+02:00</td>\n",
       "      <td>Jalgrattur pööras sõiduautole ette ja sai viga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>{'Tartu Postimees'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6838937</td>\n",
       "      <td>2019-11-30T11:04:54+02:00</td>\n",
       "      <td>Vales kohas vasakpööret sooritanud autojuht põ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>{'Tartu Postimees'}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6838618</td>\n",
       "      <td>2019-11-29T19:04:38+02:00</td>\n",
       "      <td>Galerii: Toomas Asser sai ülikooli muuseumi pü...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1425</td>\n",
       "      <td>{'Tartu Postimees'}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                   datetime  \\\n",
       "0  6839008  2019-11-30T13:50:49+02:00   \n",
       "1  6838978  2019-11-30T12:49:30+02:00   \n",
       "2  6838938  2019-11-30T11:08:41+02:00   \n",
       "3  6838937  2019-11-30T11:04:54+02:00   \n",
       "4  6838618  2019-11-29T19:04:38+02:00   \n",
       "\n",
       "                                               title  share_count  \\\n",
       "0  Tänavatantsijad tõid Leedu võistluselt Tartuss...          0.0   \n",
       "1    Tartu ärinõuandla andis välja Hea Tegu auhinnad          0.0   \n",
       "2     Jalgrattur pööras sõiduautole ette ja sai viga          0.0   \n",
       "3  Vales kohas vasakpööret sooritanud autojuht põ...          1.0   \n",
       "4  Galerii: Toomas Asser sai ülikooli muuseumi pü...         73.0   \n",
       "\n",
       "   comment_count  read_count               author  category  \n",
       "0              0          14       {'Lenel Karu'}         0  \n",
       "1              0          22  {'Tartu Postimees'}         0  \n",
       "2              0          60  {'Tartu Postimees'}         0  \n",
       "3              0         121  {'Tartu Postimees'}         0  \n",
       "4              0        1425  {'Tartu Postimees'}         1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/postimees_lemma_title.txt\", sep=\"\\t\", names=['id', 'datetime', 'title', 'share_count', 'comment_count', 'read_count', 'author'])\n",
    "data = data[1:]\n",
    "data = data.drop_duplicates(subset=['id'])\n",
    "data = data.drop(columns=['id', 'datetime', 'author'])\n",
    "\n",
    "data['comment_count'] = pd.to_numeric(data['comment_count'],errors='coerce')\n",
    "data['read_count'] = pd.to_numeric(data['read_count'],errors='coerce')\n",
    "data['share_count'] = pd.to_numeric(data['share_count'],errors='coerce')\n",
    "\n",
    "def divide(row):\n",
    "    if row.read_count < 1000:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data['category'] = data.apply(lambda i: divide(i), axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sizes of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111458, 8)\n",
      "(102563, 8)\n"
     ]
    }
   ],
   "source": [
    "print(data[data['read_count'] < 1000].shape)\n",
    "print(data[data['read_count'] >= 1000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data.title.tolist()\n",
    "titles = [str(i) for i in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text in the titles is turned into numerical feature vectors of length 1 to 3 (1-grams to 3-grams) and assigned a frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(ngram_range=(1,4))\n",
    "#count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occurences of words are turned to frequencies of the word in title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is divided into test and train and LinearSVC is used for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25471  7858]\n",
      " [ 9772 21106]]\n",
      "Classification accuracy is:  0.7254193468001932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, data.category, test_size=0.3)\n",
    "\n",
    "#clf = SGDRegressor(max_iter=10000).fit(X_train, y_train)\n",
    "#clf = SGDClassifier().fit(X_train, y_train)\n",
    "clf = LinearSVC()\n",
    "#clf = LinearSVR().fit(X_train, y_train)\n",
    "#clf = MultinomialNB(alpha=0.8).fit(X_train, y_train)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)\n",
    "print(\"Classification accuracy is: \", (confusion[0][0] + confusion[1][1]) / np.sum(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#mean_squared_error(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)\n",
    "#roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it yourself by inserting Postimees titles into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Rakverest pärit teatrimehed pälvisid stipendiumi', \n",
    "         'Erootilised jõulud - kuidas oma suhe pühade ajal uuele tasemele viia',\n",
    "         'Vanamehe lapšelapš Priidik hakkas räppariks ja avaldas nubluga hiti']\n",
    "\n",
    "lemma_titles = []\n",
    "for title in titles:\n",
    "    text = Text(str(title)).analyse('morphology')\n",
    "    lemmas = text.morph_analysis.lemma\n",
    "    new = \"\"\n",
    "    for s in lemmas:\n",
    "        new += str(s[0]) + \" \"\n",
    "    lemma_titles.append(new)\n",
    "\n",
    "X_new_counts = count_vect.transform(lemma_titles)\n",
    "X_new = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "y_pred = clf.predict(X_new)\n",
    "\n",
    "pd.DataFrame({'title': titles, 'predicted_category': y_pred})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
